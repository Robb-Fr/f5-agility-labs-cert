<!DOCTYPE html>
<head>
  
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-PPZPQ6');</script>
  <!-- End Google Tag Manager -->
    <title>F5N2 - Configuration: Knowledge</title>
  

  <meta charset="utf-8">
  <!-- Twitter Bootstrap viewport setting -->
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <!-- F5 metadata -->
  <meta name="title" content="F5N2 - Configuration: Knowledge"/>
  <meta name="product" content="Unofficial - F5 Certification Exam Prep Material"/>
  <meta name="version" content=""/>
  <meta name="updated_date"  content="2024-09-10 03:03:32"/>
  <meta name="archived" content="Archived documents excluded"/>
  <meta name="doc_type" content="Manual"/>
  <meta name="lifecycle" content="release"/>
  <meta name="Unofficial - F5 Certification Exam Prep Material" content=""/>


  

  
  <link href="https://cdn.f5.com/favicon.ico" rel="icon">

</head>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>F5N2 - Configuration: Knowledge &#8212; Unofficial - F5 Certification Exam Prep Material  documentation</title>
    <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/f5.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/f5-theme.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/CoveoFullSearch.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://use.fontawesome.com/21fb8a09c3.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <script type="text/javascript" src="../../_static/clipboard.min.js"></script>
    <script type="text/javascript" src="../../_static/copybutton.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="F5N3 - Configuration: Demonstrate" href="module3.html" />
    <link rel="prev" title="F5N1 - Management" href="module1.html" /> 
  </head><body>
  <div id="clouddocs-header"></div>

    <div id="sidebar" class="section-nav">
      
      <!--  version selector ------------------>
      <div id="version_selector_wrapper">
      </div>
      <nav class="nav-sidebartoc">

        
         <h5>Unofficial - F5 Certification Exam Prep Material  </h5>
        

        <hr>
        <span class="nav-sidebartoc">
            <p class="caption"><span class="caption-text">Intro:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html">Getting Started with the F5 Certification Program - Created 03/29/19</a></li>
</ul>
<p class="caption"><span class="caption-text">Unofficial - 101 Certification Exam Resources:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../class1/class1.html">F5 101 - App Delivery Fundamentals Exam Study Guide - Created 03/06/20</a></li>
</ul>
<p class="caption"><span class="caption-text">Unofficial - 201 Certification Exam Resources:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../class3/class3.html">F5 201 - TMOS Administration Exam Study Guide - New One Not Created Yet</a></li>
</ul>
<p class="caption"><span class="caption-text">Unofficial - 201 Certification Lab:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../class4/class4.html">F5 201 - TMOS Administration Labs (V13.1)</a></li>
</ul>
<p class="caption"><span class="caption-text">Unofficial - 202 Certification Exam Resources:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../class5/class5.html">F5 202 - Pre-Sales Fundamentals Exam Study Guide - Created 11/01/19</a></li>
</ul>
<p class="caption"><span class="caption-text">Unofficial - 301A Certification Exam Resources:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../class7/class7.html">F5 301A - BIG-IP LTM Specialist: Architect, Set-Up &amp; Deploy Exam Study Guide - Created 11/01/19</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../class8/class8.html">F5 301A - BIG-IP LTM Specialist Labs - Created 11/01/19</a></li>
</ul>
<p class="caption"><span class="caption-text">Unofficial - 301B Certification Exam Resources:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../class9/class9.html">F5 301B - BIG-IP LTM Specialist: Maintain and Troubleshoot Exam Study Guide - Created 11/01/19</a></li>
</ul>
<p class="caption"><span class="caption-text">Unofficial - 302 Certification Exam Resources:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../class11/class11.html">F5 302 - BIG-IP DNS Specialist Exam Study Guide - NOT CREATED</a></li>
</ul>
<p class="caption"><span class="caption-text">Unofficial - 303 Certification Exam Resources:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../class13/class13.html">F5 303 - BIG-IP ASM Specialist Study Guide - NOT CREATED</a></li>
</ul>
<p class="caption"><span class="caption-text">Unofficial - 304 Certification Exam Resources:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../class15/class15.html">F5 304 - BIG-IP APM Specialist Study Guide - NOT CREATED</a></li>
</ul>
<p class="caption"><span class="caption-text">Unofficial - 401 Certification Exam Resources:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../class17/class17.html">F5 401 - Security Solution Expert Study Guide - Created 09/26/18</a></li>
</ul>
<p class="caption"><span class="caption-text">Unofficial - 402 Certification Exam Resources:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../class19/class19.html">F5 402 - Cloud Solutions Study Guide - NOT CREATED</a></li>
</ul>
<p class="caption"><span class="caption-text">Unofficial - Nginx OSS Certification Exam Resources:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../class21.html">F5 N1-N4 - NGINX OSS - NOT CREATED</a></li>
</ul>

        </span><!-- Use this file to add extra links to the bottom of the ToC sidebar -->
<hr>
  <span class="nav-sidebartoc">
 <!-- insert content here -->
  </span>
      </nav>
    </div>


    <div id="right-sidebar">
      <h7 style="font-weight:normal">On this page:</h7>
      <nav class="nav-sidebartoc">
        <span class="nav-sidebartoc">
            <ul>
<li><a class="reference internal" href="#">F5N2 - Configuration: Knowledge</a><ul>
<li><a class="reference internal" href="#exam-summary">Exam summary</a></li>
<li><a class="reference internal" href="#objective-1-1-configure-nginx-as-a-load-balancer">Objective - 1.1 Configure NGINX as a load balancer</a><ul>
<li><a class="reference internal" href="#define-the-load-balancing-pools-systems">1.1 - Define the load balancing pools/systems</a></li>
<li><a class="reference internal" href="#explain-the-different-load-balancing-algorithms">1.1 - Explain the different load balancing algorithms</a></li>
<li><a class="reference internal" href="#describe-the-process-used-to-remove-a-server-from-the-pool">1.1 - Describe the process used to remove a server from the pool</a></li>
<li><a class="reference internal" href="#describe-what-happens-when-a-pool-server-goes-down">1.1 - Describe what happens when a pool server goes down</a></li>
<li><a class="reference internal" href="#explain-what-is-unique-to-nginx-as-a-load-balancer">1.1 - Explain what is unique to NGINX as a load balancer</a></li>
<li><a class="reference internal" href="#describe-how-to-configure-security">1.1 - Describe how to configure security</a></li>
<li><a class="reference internal" href="#modify-or-tune-a-memory-zone-configuration">1.1 - Modify or tune a memory zone configuration</a></li>
<li><a class="reference internal" href="#describe-how-to-configure-nginx-as-mirroring-server">1.1 - Describe how to configure NGINX as mirroring server</a></li>
<li><a class="reference internal" href="#describe-how-to-configure-nginx-as-a-layer-4-load-balancer">1.1 - Describe how to configure NGINX as a layer 4 load balancer</a></li>
<li><a class="reference internal" href="#describe-how-to-configure-nginx-as-an-api-gateway">1.1 - Describe how to configure NGINX as an API Gateway</a></li>
</ul>
</li>
<li><a class="reference internal" href="#objective-1-2-configure-nginx-as-a-content-cache-server">Objective - 1.2 Configure NGINX as a content cache server</a><ul>
<li><a class="reference internal" href="#define-a-minimum-retention-policy">1.2 - Define a minimum retention policy</a></li>
<li><a class="reference internal" href="#describe-how-to-configure-path-regex-routing">1.2 - Describe how to configure path REGEX routing</a></li>
<li><a class="reference internal" href="#describe-the-why-and-how-of-caching-in-nginx">1.2 - Describe the why and how of caching in NGINX</a></li>
<li><a class="reference internal" href="#define-the-cache-in-the-http-context">1.2 - Define the cache in the http context</a></li>
<li><a class="reference internal" href="#enable-the-cache">1.2 - Enable the cache</a></li>
<li><a class="reference internal" href="#specify-the-content-that-should-be-cached">1.2 - Specify the content that should be cached</a></li>
<li><a class="reference internal" href="#describe-different-types-of-caching">1.2 - Describe different types of caching</a></li>
<li><a class="reference internal" href="#explain-what-is-unique-to-nginx-as-a-cache-server">1.2 - Explain what is unique to NGINX as a cache server</a></li>
</ul>
</li>
<li><a class="reference internal" href="#objective-1-3-configure-nginx-as-a-web-server">Objective - 1.3 Configure NGINX as a web server</a><ul>
<li><a class="reference internal" href="#demonstrate-how-to-securely-serve-content-http-https">1.3 - Demonstrate how to securely serve content (HTTP/HTTPS)</a></li>
<li><a class="reference internal" href="#describe-the-difference-between-serving-static-content-and-dynamic-content-regex-and-variables">1.3 - Describe the difference between serving static content and dynamic content. (REGEX, and variables)</a></li>
<li><a class="reference internal" href="#describe-how-server-and-location-work">1.3 - Describe how server and location work</a></li>
<li><a class="reference internal" href="#explain-what-is-unique-to-nginx-as-a-web-server">1.3 - Explain what is unique to NGINX as a web server</a></li>
</ul>
</li>
<li><a class="reference internal" href="#objective-configure-nginx-as-a-reverse-proxy">Objective - Configure NGINX as a reverse proxy</a><ul>
<li><a class="reference internal" href="#explain-how-traffic-routing-is-handled-in-nginx-as-a-reverse-proxy">1.4 - Explain how traffic routing is handled in NGINX as a reverse proxy</a></li>
<li><a class="reference internal" href="#explain-what-is-unique-to-nginx-as-a-reverse-proxy">1.4 - Explain what is unique to NGINX as a reverse proxy</a></li>
<li><a class="reference internal" href="#configure-encryption">1.4 - Configure encryption</a></li>
<li><a class="reference internal" href="#demonstrate-how-to-manipulate-headers">1.4 - Demonstrate how to manipulate headers</a></li>
<li><a class="reference internal" href="#describe-the-difference-between-proxy-set-header-and-add-header">1.4 - Describe the difference between proxy_set_header and add_header</a></li>
<li><a class="reference internal" href="#id1">1.4 - Modify or tune a memory zone configuration</a></li>
<li><a class="reference internal" href="#describe-how-to-configure-nginx-as-socket-reverse-proxy">1.4 - Describe how to configure NGINX as socket reverse proxy</a></li>
<li><a class="reference internal" href="#describe-how-open-source-nginx-handles-health-checks-in-different-situations">1.4 - Describe how open source NGINX handles health checks in different situations</a></li>
</ul>
</li>
</ul>
</li>
</ul>

         </span>
      </nav>
    </div>





  
  <div class="main active" id="content" >
    <article class="docs-container site-article-inner">
              <!-- custom breadcrumb -->
        <h5>
            <a href="../../index.html">Unofficial - F5 Certification Exam Prep Material</a>
              &gt; <a href="../class21.html">F5 N1-N4 - NGINX OSS - NOT CREATED</a>

          <span class="right">
             <a href="../../_sources/class21/modules/module2.rst.txt" rel="nofollow">Source</a> |
             <a href="https://github.com/f5devcentral/f5-agility-labs-cert">Edit on <i class="fa fa-github" aria-hidden="true"></i></a>
          </span>
        </h5>
        <!-- end custom breadcrumb -->
      


    <!--a title="Export PDF" id="export-pdf" class="btn btn btn-link pull-right">View PDF</a-->
    <button type="button" id="export-pdf" class="btn btn-link right">PDF</button>


    
     
         <div class="sidebar" id="version-warning" style="display: none;">
           <p class="first sidebar-title">
           <span class="icon fa fa-info-circle fa-lg"></span> Version notice:</p>
           <p class="last" id="currentVersion"></p>
          </div>


     <div role="main">
        
  <div class="section" id="f5n2-configuration-knowledge">
<h1>F5N2 - Configuration: Knowledge<a class="headerlink" href="#f5n2-configuration-knowledge" title="Permalink to this headline">¶</a></h1>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<div class="section" id="exam-summary">
<h2>Exam summary<a class="headerlink" href="#exam-summary" title="Permalink to this headline">¶</a></h2>
<p>The F5 NGINX Configuration: knowledge exam is one of four NGINX exams
candidates are required to pass to achieve the F5 Certified, Administrator,
NGINX. The exams may be taken in any order. The NGINX certification is based on
NGINX Open Source Software, not NGINX+.</p>
<p>The F5 NGINX Management exam ensures that the candidates have the skills and
understanding necessary for day-to-day management of an NGINX web server
platform.</p>
<p>This module goes through all the elements evaluated as specified in the exam
blueprint and gives insights, details but above all resources to guide
candidates in their study for these exams.</p>
<p>The covered material explores the content of the Configuration: Knowledge exam,
axed around <strong>knowing how to handle use cases with configuration directives</strong>.
Although you will read here as much insight as I could grasp from the various
sources, you are strongly advised to <strong>read by yourself the very rich
documentation</strong> details as it is the core of the evaluated material.</p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="objective-1-1-configure-nginx-as-a-load-balancer">
<h2>Objective - 1.1 Configure NGINX as a load balancer<a class="headerlink" href="#objective-1-1-configure-nginx-as-a-load-balancer" title="Permalink to this headline">¶</a></h2>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<div class="section" id="define-the-load-balancing-pools-systems">
<h3>1.1 - Define the load balancing pools/systems<a class="headerlink" href="#define-the-load-balancing-pools-systems" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="http://nginx.org/en/docs/http/load_balancing.html">http://nginx.org/en/docs/http/load_balancing.html</a></p>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/load-balancer/tcp-udp-load-balancer/">https://docs.nginx.com/nginx/admin-guide/load-balancer/tcp-udp-load-balancer/</a></p>
<p><strong>upstream directive</strong></p>
<p>Defining a load balancing pool is as simple as writing the <code class="docutils literal notranslate"><span class="pre">upstream</span></code>
directive in a <code class="docutils literal notranslate"><span class="pre">http</span></code> or <code class="docutils literal notranslate"><span class="pre">stream</span></code> block. Please refer to the referenced
pages for details.</p>
<blockquote>
<div>The simplest configuration for load balancing with nginx may look like the
following:</div></blockquote>
<div class="highlight-NGINX notranslate"><div class="highlight"><pre><span></span><span class="k">http</span> <span class="p">{</span>
    <span class="kn">upstream</span> <span class="s">myapp1</span> <span class="p">{</span>
        <span class="kn">server</span> <span class="s">srv1.example.com</span><span class="p">;</span>
        <span class="kn">server</span> <span class="s">srv2.example.com</span><span class="p">;</span>
        <span class="kn">server</span> <span class="s">srv3.example.com</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="kn">server</span> <span class="p">{</span>
        <span class="kn">listen</span> <span class="mi">80</span><span class="p">;</span>

        <span class="kn">location</span> <span class="s">/</span> <span class="p">{</span>
            <span class="kn">proxy_pass</span> <span class="s">http://myapp1</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>In the example above, there are 3 instances of the same application running on
srv1-srv3. When the load balancing method is not specifically configured, it
defaults to round-robin. All requests are proxied to the server group myapp1,
and nginx applies HTTP load balancing to distribute the requests.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="explain-the-different-load-balancing-algorithms">
<h3>1.1 - Explain the different load balancing algorithms<a class="headerlink" href="#explain-the-different-load-balancing-algorithms" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/#choosing-a-load-balancing-method">https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/#choosing-a-load-balancing-method</a></p>
<p><strong>Different algorithms for different needs</strong></p>
<p>The referenced resource explains in details each algorithm. The algorithms
available in NGINX OSS are the following:</p>
<ul class="simple">
<li>default: round-robin</li>
<li>least connections with <code class="docutils literal notranslate"><span class="pre">least_conn</span></code></li>
<li>ip hash with <code class="docutils literal notranslate"><span class="pre">ip_hash</span></code></li>
<li>generic hash with <code class="docutils literal notranslate"><span class="pre">hash</span></code></li>
<li>random with <code class="docutils literal notranslate"><span class="pre">random</span></code></li>
</ul>
<p>Note that for these methods, one can also define a <code class="docutils literal notranslate"><span class="pre">weight</span></code> parameter, that
influence some server over others when making the upstream server choice with a
defined weight.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="describe-the-process-used-to-remove-a-server-from-the-pool">
<h3>1.1 - Describe the process used to remove a server from the pool<a class="headerlink" href="#describe-the-process-used-to-remove-a-server-from-the-pool" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/load-balancer/http-health-check/#passive-health-checks">https://docs.nginx.com/nginx/admin-guide/load-balancer/http-health-check/#passive-health-checks</a></p>
<p><a class="reference external" href="https://nginx.org/en/docs/http/load_balancing.html">https://nginx.org/en/docs/http/load_balancing.html</a></p>
<p><a class="reference external" href="https://nginx.org/en/docs/http/ngx_http_upstream_module.html#server">https://nginx.org/en/docs/http/ngx_http_upstream_module.html#server</a></p>
<p><strong>Manually remove a server from a pool</strong></p>
<p>Let us say you have an upstream pool such as the one showed in the following
configuration file:</p>
<div class="highlight-NGINX notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="k">upstream</span> <span class="s">backend</span> <span class="p">{</span>
    <span class="kn">server</span> <span class="s">backend1.example.com</span><span class="p">;</span>
    <span class="kn">server</span> <span class="n">backend2.example.com</span><span class="p">:</span><span class="mi">8080</span><span class="p">;</span>
    <span class="kn">server</span> <span class="n">backend2.example.com</span><span class="p">:</span><span class="mi">8081</span><span class="p">;</span>
    <span class="p">}</span>
</pre></div>
</td></tr></table></div>
<p>You may want to perform some maintenance on the server <code class="docutils literal notranslate"><span class="pre">backend1.example.com</span></code>
and therefore, temporarily remove it from the pool. Removing the line 2 and
reloading the configuration file with <code class="docutils literal notranslate"><span class="pre">nginx</span> <span class="pre">-s</span> <span class="pre">reload</span></code> will make NGINX not
choose this upstream server for any new incoming connection. Another cleaner
possibility would be to use the <code class="docutils literal notranslate"><span class="pre">down</span></code> option such as:</p>
<div class="highlight-NGINX notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="k">upstream</span> <span class="s">backend</span> <span class="p">{</span>
<span class="hll">    <span class="kn">server</span> <span class="s">backend1.example.com</span> <span class="s">down</span><span class="p">;</span>
</span>    <span class="kn">server</span> <span class="n">backend2.example.com</span><span class="p">:</span><span class="mi">8080</span><span class="p">;</span>
    <span class="kn">server</span> <span class="n">backend2.example.com</span><span class="p">:</span><span class="mi">8081</span><span class="p">;</span>
    <span class="p">}</span>
</pre></div>
</td></tr></table></div>
<p>Where you perform a minimal alteration on your file. Note that this may lead to
connection loss for clients that were proxied to the backend1 server when you
run the configuration reload command.</p>
<p id="health-check"><strong>Automatic removal with passive health checks</strong></p>
<p>NGINX also manages automatic removal of pool members using the passive health
checks. If the response from a particular server fails with an error, nginx
will mark this server as failed, and will try to avoid selecting this server
for subsequent inbound requests for a while.</p>
<p>The max_fails directive sets the number of consecutive unsuccessful attempts to
communicate with the server that should happen during fail_timeout. By default,
max_fails is set to 1. When it is set to 0, health checks are disabled for this
server. The fail_timeout parameter also defines how long the server will be
marked as failed. After fail_timeout interval following the server failure,
nginx will start to gracefully probe the server with the live client’s
requests. If the probes have been successful, the server is marked as a live
one.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="describe-what-happens-when-a-pool-server-goes-down">
<h3>1.1 - Describe what happens when a pool server goes down<a class="headerlink" href="#describe-what-happens-when-a-pool-server-goes-down" title="Permalink to this headline">¶</a></h3>
<p>This aspect is covered in the previous part on <a class="reference internal" href="#health-check">health check</a>.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="explain-what-is-unique-to-nginx-as-a-load-balancer">
<h3>1.1 - Explain what is unique to NGINX as a load balancer<a class="headerlink" href="#explain-what-is-unique-to-nginx-as-a-load-balancer" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://www.f5.com/company/events/webinars/nginx-plus-for-load-balancing-30-min">https://www.f5.com/company/events/webinars/nginx-plus-for-load-balancing-30-min</a>
(from 6:40 to 10:20 notably)</p>
<p><strong>What are the other load balancing methods</strong></p>
<dl class="docutils">
<dt>DNS Rounds Robin</dt>
<dd><p class="first">This method is quite simple and can be easily and cheaply configured: to
load balance between 3 servers with 3 different IPs, the DNS record for the
service (example.com for example) is configured to one element among an
array of 3 IP addresses. Clients, receiving these, will contact the server
with the received IP address, allowing to distribute load among clients as
long as the DNS server returns different results to different clients.</p>
<p class="last">However, this lacks on the update speed: updating DNS records can take time
and a server that is down may be served to some client for a long time.
Also, this method does not scale well as it requires managing every growing
DNS records which can be complicated.</p>
</dd>
<dt>Hardware L4 load balancer</dt>
<dd>These are advanced network switches that do not handle a full TCP stack but
stream TCP packets and track the TCP sessions using the attributes they
find in the TCP header. They deliver great performances but are limited in
terms of available features: out of order and broken TCP packets are not
easy to handle and lead to a reduced flexibility.</dd>
<dt>Cloud solutions</dt>
<dd>Cloud providers often provide their own load balancing systems (Amazon’s
Elastic Load Balancer for example). However, these totally depend on the
exposed interface from the Cloud provider’s system, potentially giving a
lower flexibility.</dd>
</dl>
<p><strong>Where NGINX stands and what challenges it can overcome</strong></p>
<p>NGINX is in the category of the Software load balancer. This refers to reverse
proxy systems: these are software applications running on machines having their
own full TCP stack (Linux or FreeBSD machines for example). The particularity
is that it terminates the TCP connection and handles it. It afterward processes
the content of the connection as desired, and reopen a TCP connection to the
upstream server, using any implementable software method to load balance
between different servers. This gives the maximum degree of flexibility to
control the received connection and stream and apply logic to ensure
performance and security.</p>
<p>For example, with NGINX, one can perform load balancing depending on HTTP
content (session cookies, request URIs, …) as the reverse proxy terminates
the TCP connection, it has the ability to use any L4-L7 information to perform
load balancing decision.</p>
<p>Also, NGINX being implemented using low level performant C code, it benefits
from excellent performances despite being software based, which is a key aspect
to efficient load balancing.</p>
<p>The following diagrams picture the different ideologies between the different
types of load balancers.</p>
<a class="reference internal image-reference" href="../../_images/load-balancers-dns.excalidraw.svg"><div align="center" class="align-center"><img alt="Diagram load balancer DNS" src="../../_images/load-balancers-dns.excalidraw.svg" width="1200px" /></div>
</a>
<a class="reference internal image-reference" href="../../_images/load-balancers-l4.excalidraw.svg"><div align="center" class="align-center"><img alt="Diagram load balancer L4" src="../../_images/load-balancers-l4.excalidraw.svg" width="1200px" /></div>
</a>
<a class="reference internal image-reference" href="../../_images/load-balancers-software.excalidraw.svg"><div align="center" class="align-center"><img alt="Diagram software load balancer" src="../../_images/load-balancers-software.excalidraw.svg" width="1200px" /></div>
</a>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="describe-how-to-configure-security">
<span id="module2-describe-configure-security"></span><h3>1.1 - Describe how to configure security<a class="headerlink" href="#describe-how-to-configure-security" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/security-controls/">https://docs.nginx.com/nginx/admin-guide/security-controls/</a></p>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/monitoring/logging/">https://docs.nginx.com/nginx/admin-guide/monitoring/logging/</a></p>
<p><strong>L4-L7 security</strong></p>
<p>This given objective may sound quite vague, and it is not clear why it stands
in this section about load balancing as it could be a section in itself.
Considering this, the reader is advised to be familiar with all the NGINX
security controls available in NGINX OSS that we will list here and are
detailed in the linked documentation.</p>
<ul class="simple">
<li>NGINX as an HTTPS/SSL server: NGINX can handle and terminate TLS/SSL
communications. The simple default but customizable at will principle also
applies here: 3 directives allow setting up NGINX as an HTTPS reverse proxy
load balancer, but other options can be enabled (mTLS, OCSP, SNI
validation…). Note these are available in <code class="docutils literal notranslate"><span class="pre">http</span> <span class="pre">{}</span></code> and <code class="docutils literal notranslate"><span class="pre">stream</span> <span class="pre">{}</span></code>
blocks.</li>
<li>NGINX as a perimeter authentication system: NGINX supports authentication
protocols (limited in NGINX OSS) to ensure the desired <code class="docutils literal notranslate"><span class="pre">server</span> <span class="pre">{}</span></code> or
<code class="docutils literal notranslate"><span class="pre">location</span> <span class="pre">{}</span></code> blocks are protected and authenticated.</li>
<li>Rate/bandwidth control: NGINX can be configured to limit the request
rate/amount or the served bandwidth to some clients to prevent abuses.</li>
<li>IP based restrictions: NGINX can restrict access to some routes or some
servers based on the client’s IP.</li>
<li>NGINX as an HTTPS/SSL client: NGINX can finally handle secured connections to
upstream servers with again, simple defaults and some granular control to
enable options.</li>
</ul>
<p>Also, considering observability as a security property, take note of the
logging configuration of NGINX, notably its centralization capabilities with
easy to configure log sending to a syslog server.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="modify-or-tune-a-memory-zone-configuration">
<h3>1.1 - Modify or tune a memory zone configuration<a class="headerlink" href="#modify-or-tune-a-memory-zone-configuration" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html#limit_conn_zone">http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html#limit_conn_zone</a></p>
<p><a class="reference external" href="http://nginx.org/en/docs/http/ngx_http_limit_req_module.html#limit_req_zone">http://nginx.org/en/docs/http/ngx_http_limit_req_module.html#limit_req_zone</a></p>
<p><a class="reference external" href="http://nginx.org/en/docs/http/ngx_http_js_module.html#js_shared_dict_zone">http://nginx.org/en/docs/http/ngx_http_js_module.html#js_shared_dict_zone</a></p>
<p><a class="reference external" href="http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_path">http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_path</a></p>
<p><a class="reference external" href="http://nginx.org/en/docs/http/ngx_http_upstream_module.html#zone">http://nginx.org/en/docs/http/ngx_http_upstream_module.html#zone</a></p>
<p><strong>Memory zones in NGINX</strong></p>
<p>When configuring memory zones in NGINX, we generally refer to shared memory
zones, as seen and explained in <a class="reference internal" href="module1.html#module1-shared-memory-zones"><span class="std std-ref">the previous module</span></a>. To modify or tune these, we must first identify where they
appear in our NGINX configurations. In NGINX OSS, shared memory zones can be
configured in the following contexts:</p>
<ul class="simple">
<li>The connection limiting: sharing across worker the state of clients
regarding the amount of connection requests.</li>
<li>The request limiting: sharing across worker the state of clients regarding
the amount and nature of HTTP requests.</li>
<li>The JavaScript shared dictionary: sharing across workers JS structures in the
form of dictionary.</li>
<li>The proxy caching: sharing across workers the key/value pairs associating
requests parameters with cached content location on the disk.</li>
<li>The upstream pools: sharing across workers the state of upstream services of
pools for updating their status (alive, down, served X times, …)</li>
</ul>
<p><strong>What can be configured and tuned</strong></p>
<p>In each of the aforementioned contexts, different directives allow configuring
the shared memory zones corresponding. For most of these, this zone has only 2
parameters: a name (used to identify a same zone multiple times in the config),
and a size in bytes.</p>
<p>The size parameter can be tuned and engineered to correspond to the nature of
the application and the server’s resources. For example, knowing that a shared
JS dictionary should only have a few small entries, on can allocate only a few
kilobytes preventing the allocation of megabytes of memory and not using it.</p>
<p>For details on the different syntaxes, the reader should refer to the mentioned
links to the documentation.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="describe-how-to-configure-nginx-as-mirroring-server">
<h3>1.1 - Describe how to configure NGINX as mirroring server<a class="headerlink" href="#describe-how-to-configure-nginx-as-mirroring-server" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://alex.dzyoba.com/blog/nginx-mirror/">https://alex.dzyoba.com/blog/nginx-mirror/</a></p>
<p><a class="reference external" href="http://nginx.org/en/docs/http/ngx_http_mirror_module.html">http://nginx.org/en/docs/http/ngx_http_mirror_module.html</a></p>
<p><a class="reference external" href="https://thelinuxnotes.com/index.php/mirroring-requests-to-another-server-with-nginx/">https://thelinuxnotes.com/index.php/mirroring-requests-to-another-server-with-nginx/</a></p>
<p><strong>The concept of mirroring requests in NGINX</strong></p>
<p>In the context of reverse proxying, request mirroring refers to making the
reverse proxy, proxy requests to a mirroring server, “as if” it was an actual
backend upstream server. However, the specificity lies in the fact that NGINX
does not actually forward the mirror server’s response back to the client. This
for example allows testing a new, off-production backend server with real
clients’ requests and assess its functionalities before pushing it to
production.</p>
<p>The following diagram from <a class="reference external" href="https://alex.dzyoba.com/blog/nginx-mirror/">Alex Dzyoba’s blog</a> provides a visual representation
of a mirroring setup where NGINX would both, proxy the actual client’s request
to the real backend server, and mirroring this request to a test server.</p>
<a class="reference internal image-reference" href="../../_images/nginx-mirror-mirror-setup.png"><img alt="Diagram of a mirroring server setup with NGINX" src="../../_images/nginx-mirror-mirror-setup.png" style="height: 400px;" /></a>
<p><strong>Configure NGINX to mirror requests</strong></p>
<p>NGINX uses the directives from the <code class="docutils literal notranslate"><span class="pre">ngx_http_mirror_module</span></code> to implement the
mirroring.</p>
<p>The following configuration defines 2 locations: the first where NGINX should:</p>
<ol class="arabic simple">
<li>mirror the client’s request to its <code class="docutils literal notranslate"><span class="pre">/mirror</span></code> URI</li>
<li>proxy the request to the real backend, picked from the upstream pool named
<code class="docutils literal notranslate"><span class="pre">backend</span></code>.</li>
</ol>
<p>The second location is internal (meaning it can only be reached by NGINX
itself, not from the outside), and defines what should happen to the requests
made to the <code class="docutils literal notranslate"><span class="pre">/mirror</span></code> endpoint. They should be proxied to another backend,
picked from the <code class="docutils literal notranslate"><span class="pre">test_backend</span></code> pool.</p>
<div class="highlight-NGINX notranslate"><div class="highlight"><pre><span></span><span class="k">location</span> <span class="s">/</span> <span class="p">{</span>
    <span class="kn">mirror</span> <span class="s">/mirror</span><span class="p">;</span>
    <span class="kn">proxy_pass</span> <span class="s">http://backend</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">location</span> <span class="p">=</span> <span class="s">/mirror</span> <span class="p">{</span>
    <span class="kn">internal</span><span class="p">;</span>
    <span class="kn">proxy_pass</span> <span class="s">http://test_backend</span><span class="nv">$request_uri</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="describe-how-to-configure-nginx-as-a-layer-4-load-balancer">
<h3>1.1 - Describe how to configure NGINX as a layer 4 load balancer<a class="headerlink" href="#describe-how-to-configure-nginx-as-a-layer-4-load-balancer" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/load-balancer/tcp-udp-load-balancer/">https://docs.nginx.com/nginx/admin-guide/load-balancer/tcp-udp-load-balancer/</a></p>
<p><strong>TCP/UDP load balancing</strong></p>
<p>In the same fashion as NGINX can be configured as a Layer 7 (HTTP) load
balancer, the same can be done at the Layer 4 with a similar syntax: one must
configure an upstream servers group with the <code class="docutils literal notranslate"><span class="pre">upstream</span></code> directive and can
afterward use the <code class="docutils literal notranslate"><span class="pre">proxy_pass</span></code> directive to proxy the requests at layer 4 to
the upstream pool.</p>
<p>The following configuration defines an upstream pool composed of 3 servers: the
first 3 are active while the last 2 are backup (they receive requests only when
one of the active server is down). The first server is preferred in the load
balancing algorithm by a factor of 5. The load balancing algorithm uses the
hash algorithm by taking the remote client’s address as a key.</p>
<div class="highlight-NGINX notranslate"><div class="highlight"><pre><span></span><span class="k">upstream</span> <span class="s">backend</span> <span class="p">{</span>
    <span class="kn">hash</span> <span class="nv">$remote_addr</span><span class="p">;</span>

    <span class="kn">server</span> <span class="n">backend1.example.com</span><span class="p">:</span><span class="mi">12345</span>  <span class="s">weight=5</span><span class="p">;</span>
    <span class="kn">server</span> <span class="n">backend2.example.com</span><span class="p">:</span><span class="mi">12345</span><span class="p">;</span>
    <span class="kn">server</span> <span class="s">unix:/tmp/backend3</span><span class="p">;</span>

    <span class="kn">server</span> <span class="n">backup1.example.com</span><span class="p">:</span><span class="mi">12345</span>   <span class="s">backup</span><span class="p">;</span>
    <span class="kn">server</span> <span class="n">backup2.example.com</span><span class="p">:</span><span class="mi">12345</span>   <span class="s">backup</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">server</span> <span class="p">{</span>
    <span class="kn">listen</span> <span class="mi">12346</span><span class="p">;</span>
    <span class="kn">proxy_pass</span> <span class="s">backend</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="describe-how-to-configure-nginx-as-an-api-gateway">
<h3>1.1 - Describe how to configure NGINX as an API Gateway<a class="headerlink" href="#describe-how-to-configure-nginx-as-an-api-gateway" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://www.f5.com/company/blog/nginx/deploying-nginx-plus-as-an-api-gateway-part-1">https://www.f5.com/company/blog/nginx/deploying-nginx-plus-as-an-api-gateway-part-1</a></p>
<p><a class="reference external" href="https://www.f5.com/company/blog/nginx/deploying-nginx-plus-as-an-api-gateway-part-2-protecting-backend-services">https://www.f5.com/company/blog/nginx/deploying-nginx-plus-as-an-api-gateway-part-2-protecting-backend-services</a></p>
<p><a class="reference external" href="https://www.f5.com/company/blog/nginx/deploying-nginx-plus-as-an-api-gateway-part-3-publishing-grpc-services">https://www.f5.com/company/blog/nginx/deploying-nginx-plus-as-an-api-gateway-part-3-publishing-grpc-services</a></p>
<p><strong>NGINX as an API gateway</strong></p>
<p>To answer these aspects, I could not propose a better guide than the one you
can find in the references, written by Liam Crilly. The following is the
article’s table of content, curated to remove NGINX+ specific content as it is
not covered by the certification.</p>
<ul class="simple">
<li>Configuring the API gateway<ul>
<li>Introducing the Warehouse API</li>
<li>Organizing the NGINX Configuration</li>
<li>Defining the Top-Level API Gateway</li>
<li>Single-Service vs. Microservice API Backends</li>
<li>Defining the Warehouse API<ul>
<li>Choosing Broad vs. Precise Definition for APIs</li>
<li>Rewriting Client Requests to Handle Breaking Changes</li>
</ul>
</li>
<li>Responding to Errors</li>
<li>Implementing Authentication<ul>
<li>API Key Authentication</li>
</ul>
</li>
</ul>
</li>
<li>Protecting backend services<ul>
<li>Rate Limiting</li>
<li>Enforcing Specific Request Methods</li>
<li>Applying Fine-Grained Access Control<ul>
<li>Controlling Access to Specific Resources</li>
<li>Controlling Access to Specific Methods</li>
<li>Controlling Request Sizes</li>
<li>Validating Request Bodies</li>
<li>A Note about the <code class="docutils literal notranslate"><span class="pre">$request_body</span></code> Variable</li>
</ul>
</li>
</ul>
</li>
<li>Publishing gRPC Services<ul>
<li>Defining the gRPC Gateway</li>
<li>Running Sample gRPC Services<ul>
<li>Routing gRPC Requests</li>
<li>Precise Routing</li>
</ul>
</li>
<li>Responding to Errors</li>
<li>Authenticating Clients with gRPC Metadata</li>
<li>Applying Rate Limiting and Other API Gateway Controls</li>
</ul>
</li>
</ul>
<p>These constitute an excellent recipe for configuring NGINX as an API gateway.
Of course not all elements need to be applied, and some elements may already be
performed by the application (controlling the body content), but this recipe
shows how to take any app (even a legacy or lazy one) and configure a secure
and efficient API gateway.</p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
</div>
<div class="section" id="objective-1-2-configure-nginx-as-a-content-cache-server">
<h2>Objective - 1.2 Configure NGINX as a content cache server<a class="headerlink" href="#objective-1-2-configure-nginx-as-a-content-cache-server" title="Permalink to this headline">¶</a></h2>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<div class="section" id="define-a-minimum-retention-policy">
<h3>1.2 - Define a minimum retention policy<a class="headerlink" href="#define-a-minimum-retention-policy" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://blog.nginx.org/blog/nginx-caching-guide">https://blog.nginx.org/blog/nginx-caching-guide</a></p>
<p><a class="reference external" href="https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_path">https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_path</a></p>
<p><a class="reference external" href="https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_use_stale">https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_use_stale</a></p>
<p>DEJONGHE, NGINX COOKBOOK Advanced Recipes for High -Performance Load
Balancing., 41-41.</p>
<p><strong>Minimum retention policy</strong></p>
<p>When speaking of a caching system, a minimum retention policy refers to the
minimum time an element is accessible from a cached location. Concretely,
imagine we cache the content served from the upstream server at endpoint
<cite>http://upstream/data/1</cite>. A minimum retention policy defines the minimum time
(m seconds) NGINX would keep the cached version of the upstream’s response: we
would be sure to always have the cached version for m seconds after the initial
cache insertion.</p>
<p><strong>NGINX cache minimum retention</strong></p>
<p>Strictly speaking, I cannot see how to configure NGINX in a way that makes it
purposefully enforce a minimum retention policy. The closest aspect of NGINX
that may coincide with this policy is the ability for NGINX to serve cached
stale content in case of an error.</p>
<div class="highlight-NGINX notranslate"><div class="highlight"><pre><span></span><span class="k">proxy_cache_use_stale</span> <span class="s">error</span> <span class="s">timeout</span> <span class="s">invalid_header</span> <span class="s">updating</span>
  <span class="s">http_500</span> <span class="s">http_502</span> <span class="s">http_503</span> <span class="s">http_504</span>
  <span class="s">http_403</span> <span class="s">http_404</span> <span class="s">http_429</span><span class="p">;</span>
</pre></div>
</div>
<p>The above directive indicates that NGINX should use cache content, even if it
is stale, upon upstream servers responding error codes 500, 502, 503, 504, 403,
404 or 429. It also specifies that NGINX should do the same in case the
upstream request timed out, it answered with invalid headers, it encountered an
error or also when the cache is being updated (so that NGINX can answer before
the cache gets fully updated but with a stale response).</p>
<p>The parameters are the ones found in the variable <a class="reference external" href="https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_next_upstream">proxy_next_upstream</a>.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="describe-how-to-configure-path-regex-routing">
<span id="module2-configure-routing"></span><h3>1.2 - Describe how to configure path REGEX routing<a class="headerlink" href="#describe-how-to-configure-path-regex-routing" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://www.f5.com/company/blog/nginx/regular-expression-tester-nginx">https://www.f5.com/company/blog/nginx/regular-expression-tester-nginx</a></p>
<p><a class="reference external" href="https://nginx.org/en/docs/http/ngx_http_core_module.html#location">https://nginx.org/en/docs/http/ngx_http_core_module.html#location</a></p>
<p><a class="reference external" href="https://nginx.org/en/docs/http/request_processing.html">https://nginx.org/en/docs/http/request_processing.html</a></p>
<p><strong>URI routing in NGINX</strong></p>
<p>When NGINX receives a request, it first tries to find a matching <code class="docutils literal notranslate"><span class="pre">server</span> <span class="pre">{}</span></code>
block to send the request to. Once this is done, NGINX processes the request’s
URI to find a matching <code class="docutils literal notranslate"><span class="pre">location</span> <span class="pre">{}</span></code> block among the one in the matched
server. This process is crucial and very error-prone, the reader must
familiarize with the location matching process to prevent errors. The matching
process is described as follows:</p>
<blockquote>
<div><p>The matching is performed against a normalized URI, after decoding the text
encoded in the “%XX” form, resolving references to relative path components
“.” and “..”, and possible compression of two or more adjacent slashes into a
single slash.</p>
<p>A location can either be defined by a prefix string, or by a regular
expression. Regular expressions are specified with the preceding “~*”
modifier (for case-insensitive matching), or the “~” modifier (for
case-sensitive matching). To find location matching a given request, nginx
first checks locations defined using the prefix strings (prefix locations).
Among them, the location with the longest matching prefix is selected and
remembered. Then regular expressions are checked, in the order of their
appearance in the configuration file. The search of regular expressions
terminates on the first match, and the corresponding configuration is used.
If no match with a regular expression is found then the configuration of the
prefix location remembered earlier is used.</p>
<p>Location blocks can be nested, with some exceptions mentioned below.</p>
<p>For case-insensitive operating systems such as macOS and Cygwin, matching
with prefix strings ignores a case (0.7.7). However, comparison is limited to
one-byte locales.</p>
<p>Regular expressions can contain captures (0.7.40) that can later be used in
other directives.</p>
<p>If the longest matching prefix location has the “^~” modifier then regular
expressions are not checked.</p>
<p>Also, using the “=” modifier it is possible to define an exact match of URI
and location. If an exact match is found, the search terminates. For example,
if a “/” request happens frequently, defining “location = /” will speed up
the processing of these requests, as search terminates right after the first
comparison. Such a location cannot obviously contain nested locations.</p>
</div></blockquote>
<p>Shortening this description is error-prone, therefore we advise familiarizing
with it. The following points can be surprising:</p>
<ul class="simple">
<li>By default, a REGEX match supersedes a prefix match (irrelevantly of the
length of the match)</li>
<li>Options “=” and “^~” disable the checking of REGEX matches</li>
<li>The first matched REGEX stops the matching check process: the order matters
and there is not such thing as longest matched REGEX (fortunately so)</li>
</ul>
<p>Among other points. The referenced [blog
post](<a class="reference external" href="https://www.f5.com/company/blog/nginx/regular-expression-tester-nginx">https://www.f5.com/company/blog/nginx/regular-expression-tester-nginx</a>)
from Rick Nelson gathers interesting examples and an explanation for a tester
software you can run to check which routes match a given REGEX location. Check
examples from the NGINX documentation to familiarize with REGEX and locations
definitions in NGINX.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="describe-the-why-and-how-of-caching-in-nginx">
<h3>1.2 - Describe the why and how of caching in NGINX<a class="headerlink" href="#describe-the-why-and-how-of-caching-in-nginx" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/content-cache/content-caching/">https://docs.nginx.com/nginx/admin-guide/content-cache/content-caching/</a></p>
<p>Kapranoff, Nginx Troubleshooting, 82.</p>
<p><a class="reference external" href="http://nginx.org/en/docs/http/ngx_http_proxy_module.html">http://nginx.org/en/docs/http/ngx_http_proxy_module.html</a></p>
<p><strong>Caching reduces load and speeds up</strong></p>
<p>The main reasons why one would like to cache in NGINX in because NGINX presents
the advantage of being an intermediate between the client and the upstream
servers. This leads to the following advantages:</p>
<ul class="simple">
<li>Caching at NGINX reduces load on the backend servers by processing and
serving some requests without having to re-ask the upstream to do it.</li>
<li>Caching at NGINX speeds up the response process as there are fewer
intermediates that need to be contacted to answer the client’s request
(everything between NGINX and the backend server is not involved when serving
a cached response).</li>
</ul>
<p><strong>How does NGINX enable caching</strong></p>
<p>There are different ways to ensure the served web content gets cached with
NGINX. We will here focus on the literal sense of using NGINX “as a caching
server”; namely, we will see how to make NGINX being the node serving cached
content in the web content retrieval process. Nonetheless, when engineering
your caching system, do not forget that you can make use (and use NGINX’s
capabilities to do so) of the HTTP headers such as <code class="docutils literal notranslate"><span class="pre">Cache-Control</span></code>. But this
makes web client become the caching actors, and we may want to get more control
on cached content by making it closer to the upstream servers. This is where
NGINX comes in handy.</p>
<p>Enabling caching on NGINX means making NGINX storing the content obtained from
the upstream servers to serve it later, when an “identical” requests comes in,
without having to contact the upstream server. This raises two interesting
points that we will immediately answer:</p>
<ul class="simple">
<li>Where is this content cached?<ul>
<li>The content gets cached on the NGINX host’s file system, at the path
specified with the <code class="docutils literal notranslate"><span class="pre">proxy_cache_path</span></code> directive. Generally, this means it
gets stored on the disk of the machine where NGINX is hosted. Nonetheless,
it is absolutely compatible with systems having other kinds of storage
mounted on the filesystem (you could mount a NFS or RAMFS endpoints and
store the cache there). Note that this is where the actual cache content
(HTML, JSON, or any web result returned by the upstream server to be sent
to the client). Caching in NGINX also involves cache keys that are
discussed in the next point.</li>
</ul>
</li>
<li>When does NGINX know how to serve cached content and when the request should
be forwarded to upstream?<ul>
<li>When NGINX performs content caching and receives a new request, it must
decide between “forwarding the request to upstream” or “hitting cache and
serving what I cached earlier”. Of course the algorithm to decide on this
is more complex that what we will explain, but the idea stays the same.
NGINX uses under the hood hash tables to map requests to cached content.
Therefore, to know if cached content already exists for some kind of
request, it will see if the request’s key matches an existing value. The
keys are stored in a shared memory zone defines with the
<code class="docutils literal notranslate"><span class="pre">proxy_cache_path</span></code> directive. The <code class="docutils literal notranslate"><span class="pre">proxy_cache_key</span></code> directives helps to
define what NGINX considers as two identical requests. By default, requests
with the same <code class="docutils literal notranslate"><span class="pre">$scheme$proxy_host$uri$is_args$args</span></code> are considered
identical and get served the same cached content. Otherwise, if not
matching value is found or if the cached content is stale, NGINX will
forward the request to an upstream server.</li>
</ul>
</li>
</ul>
<p>These are the basics of how NGINX allows caching the content when placed as a
reverse proxy: it stores in its own file system the files served by upstream to
client, and tries to match incoming requests with the cached ones, serving the
cached ones when possible.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="define-the-cache-in-the-http-context">
<span id="module2-define-cache"></span><h3>1.2 - Define the cache in the http context<a class="headerlink" href="#define-the-cache-in-the-http-context" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/content-cache/content-caching/">https://docs.nginx.com/nginx/admin-guide/content-cache/content-caching/</a></p>
<p><a class="reference external" href="http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_path">http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_path</a></p>
<p><strong>Simple cache definition in http context</strong></p>
<p>Although many configurations are possible, quickly getting started with NGINX
default cache is as simple as defining a <code class="docutils literal notranslate"><span class="pre">proxy_cache_path</span></code> directive in the
<code class="docutils literal notranslate"><span class="pre">http</span> <span class="pre">{}</span></code> context, along with the <code class="docutils literal notranslate"><span class="pre">proxy_cache</span></code> directive in the context
where you want to have caching (a whole server, a location, etc.).</p>
<p>The following gives a quick example:</p>
<div class="highlight-NGINX notranslate"><div class="highlight"><pre><span></span><span class="k">http</span> <span class="p">{</span>
    <span class="c1"># ...</span>
    <span class="kn">proxy_cache_path</span> <span class="s">/data/nginx/cache</span> <span class="s">keys_zone=mycache:10m</span><span class="p">;</span>
    <span class="kn">server</span> <span class="p">{</span>
        <span class="kn">proxy_cache</span> <span class="s">mycache</span><span class="p">;</span>
        <span class="kn">location</span> <span class="s">/</span> <span class="p">{</span>
            <span class="kn">proxy_pass</span> <span class="s">http://localhost:8000</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>This defines content caching where cached files are stored in the file system
at <code class="docutils literal notranslate"><span class="pre">/data/nginx/cache</span></code>, and cache keys are stored in a shared memory zone
named <code class="docutils literal notranslate"><span class="pre">mycache</span></code>, a zone of 10 megabytes.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Although this is not directly linked to this evaluation point, please note
the following: by default the cache keys quite matches the following 5-tuple
<code class="docutils literal notranslate"><span class="pre">$scheme$proxy_host$uri$is_args$args</span></code>. This means that 2 users querying
<code class="docutils literal notranslate"><span class="pre">https://example.com/myprofile</span></code> should, in the eyes of NGINX, be served the
same cached content. If Bob’s profile is loaded in the cache, then Alice’s
request will be served the same cached content page that could contain
sensible information. To avoid this, defining new cache keys such as
<code class="docutils literal notranslate"><span class="pre">$host$request_uri$cookie_user</span></code> could prevent this issue, assuming you have
an authentication session cookie named USER and your endpoint is
authenticated through this cookie. Indeed, Alice and Bob’s cookies will not
match and therefore, the requests will not be considered identical.</p>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="enable-the-cache">
<h3>1.2 - Enable the cache<a class="headerlink" href="#enable-the-cache" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference internal" href="#module2-define-cache"><span class="std std-ref">previous part</span></a> basically covers this. The
caching is actually enabled through the <code class="docutils literal notranslate"><span class="pre">proxy_cache</span></code> directive which makes
responses from a given context actually cached.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="specify-the-content-that-should-be-cached">
<h3>1.2 - Specify the content that should be cached<a class="headerlink" href="#specify-the-content-that-should-be-cached" title="Permalink to this headline">¶</a></h3>
<p>Kapranoff, Nginx Troubleshooting, 82.</p>
<p><strong>When caching gets most useful</strong></p>
<p>This question is of course open-ended. However, the caching algorithm is best
when optimizing the following aspects:</p>
<ul class="simple">
<li>The cached content should not change often and be long-lived static.
Otherwise you would often have to re-populate your cache or worse, serve
stale content when it is not desired.</li>
<li>The cached content should be the one queried often. Indeed, you do not want
to use memory resources for content that is useful to a very few users.</li>
</ul>
<p>Therefore, the answer to “what should be cached” may vary on your application,
however, some files often match these criteria in many case static files such
as style sheets or static scripts that are required upon every request and
generally are not updated on any release (or at least, serving stale style
might still allow your service to function and occur minimal impact).</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="describe-different-types-of-caching">
<h3>1.2 - Describe different types of caching<a class="headerlink" href="#describe-different-types-of-caching" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference internal" href="module1.html#module1-describe-nginx-caching"><span class="std std-ref">previous module</span></a> already goes
through details on different types of caching along with references on the
topic.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="explain-what-is-unique-to-nginx-as-a-cache-server">
<h3>1.2 - Explain what is unique to NGINX as a cache server<a class="headerlink" href="#explain-what-is-unique-to-nginx-as-a-cache-server" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_path">http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_path</a></p>
<p><strong>Interests of caching at the reverse proxy layer</strong></p>
<p>In the same idea as “what is unique to NGINX” as a load balancer, we, among
other things, find NGINX’s uniqueness in its interesting position on the path
between clients and upstream servers. Indeed, caching at the reverse proxy has
both advantages:</p>
<ul class="simple">
<li>It effectively reduces load on the backend servers, as a cache hit results in
the server not being queried. This can be done with zero modification of the
upstream server’s code which may be handy when dealing with legacy or
non-controllable applications.</li>
<li>It leaves control in your hands. A disadvantage of caching on the clients’
devices is that if you make a mistake (setting a client cache time limit too
high for example), clients may be left with stale data and wrongly not
re-emit requests to your servers. Having NGINX caching allows you, as an
admin, tu purge caches if needed and control it on your end.</li>
</ul>
<p><strong>Optimized and controllable caching</strong></p>
<p>The above is true for any caching implemented by a reverse proxy. NGINX is
particularly good because it comes with great optimizations (e.g.: the caching
keys are stored in a shared memory zone, this is non-trivial and allows sharing the cache population work performed by the different workers and leverage
hardware with high parallelism capabilities) that are very easy to configure
out of the box.</p>
<p>On another hands, I think it is important to speak about the controllability
you get when caching with NGINX. Notably, you should visit the documentation
page about <a class="reference external" href="http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_path">proxy_cache_path</a>
directive. You can for example define parameters on how and when to purge
files, along with directives controlling how should concurrent workers fetching
a cacheable data behave. This allows you to define your own thresholds between
serving cached data at all cost or just using cache as a circumstantial
performance bonus, depending on your business needs.</p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
</div>
<div class="section" id="objective-1-3-configure-nginx-as-a-web-server">
<h2>Objective - 1.3 Configure NGINX as a web server<a class="headerlink" href="#objective-1-3-configure-nginx-as-a-web-server" title="Permalink to this headline">¶</a></h2>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<div class="section" id="demonstrate-how-to-securely-serve-content-http-https">
<span id="module2-securely-serve-content"></span><h3>1.3 - Demonstrate how to securely serve content (HTTP/HTTPS)<a class="headerlink" href="#demonstrate-how-to-securely-serve-content-http-https" title="Permalink to this headline">¶</a></h3>
<p>DEJONGHE, NGINX COOKBOOK Advanced Recipes for High -Performance Load
Balancing., 77, 84-88.</p>
<p><a class="reference external" href="https://nginx.org/en/docs/http/configuring_https_servers.html">https://nginx.org/en/docs/http/configuring_https_servers.html</a></p>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/security-controls/">https://docs.nginx.com/nginx/admin-guide/security-controls/</a></p>
<p>Kapranoff, Nginx Troubleshooting, 117.</p>
<p><a class="reference external" href="https://www.cyberciti.biz/tips/linux-unix-bsd-nginx-webserver-security.html">https://www.cyberciti.biz/tips/linux-unix-bsd-nginx-webserver-security.html</a></p>
<p><a class="reference external" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy">https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy</a></p>
<p><a class="reference external" href="https://blog.nginx.org/blog/http-strict-transport-security-hsts-and-nginx">https://blog.nginx.org/blog/http-strict-transport-security-hsts-and-nginx</a></p>
<p><strong>General security aspects</strong></p>
<p>The <a class="reference internal" href="#module2-describe-configure-security"><span class="std std-ref">previous part</span></a> already gives
insights on what settings can be adjusted to control security aspects of an
HTTP/HTTPS server. Security of course is a tremendously vast topic, and we
could not cover it all in this point. We will try to cover the most important
aspects and, as the objective asks for demonstrative capabilities, mostly
provide detailed examples of concrete security configurations.</p>
<p><strong>Authentication</strong></p>
<p>NGINX OSS proposes 2 ways to authenticate requests and protect locations based
on authentication + authorization rules: HTTP Basic authentication and
sub-request results. You will find more details on this in :ref:` module 3
&lt;module3 demonstrate authenticate&gt;`.</p>
<p><strong>Client-Reverse Proxy flux security</strong></p>
<p>Securing the connection between the connecting client and NGINX can be achieved
with the various capabilities for setting up NGINX as an HTTPS server. You will
find more details on this point in <a class="reference internal" href="module3.html#module3-configure-certificates"><span class="std std-ref">module 3</span></a>.</p>
<p><strong>Reverse Proxy-Upstream servers security</strong></p>
<p>In order to make sure the communication between NGINX and the upstream servers
is secured, one can configure HTTPS communication between NGINX and the
upstream server when proxy passing the requests. The following example shows
how to do it:</p>
<div class="highlight-NGINX notranslate"><div class="highlight"><pre><span></span><span class="k">location</span> <span class="s">/</span> <span class="p">{</span>
  <span class="kn">proxy_pass</span> <span class="s">https://upstream.example.com</span><span class="p">;</span>
  <span class="kn">proxy_ssl_verify</span> <span class="no">on</span><span class="p">;</span>
  <span class="kn">proxy_ssl_protocols</span> <span class="s">TLSv1.3</span><span class="p">;</span>

  <span class="kn">proxy_ssl_certificate</span>     <span class="s">/etc/nginx/client.pem</span><span class="p">;</span>
  <span class="kn">proxy_ssl_certificate_key</span> <span class="s">/etc/nginx/client.key</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">proxy_pass</span></code> directive uses the <code class="docutils literal notranslate"><span class="pre">https</span></code> scheme, which enables
HTTPS with the upstream. The <code class="docutils literal notranslate"><span class="pre">proxy_ssl_verify</span></code> directive is set to <code class="docutils literal notranslate"><span class="pre">on</span></code> to
make sure that NGINX verifies the upstream server’s certificate (<a class="reference external" href="https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_ssl_verify">by default</a>,
this is set to <code class="docutils literal notranslate"><span class="pre">off</span></code>). The <code class="docutils literal notranslate"><span class="pre">proxy_ssl_protocols</span></code> limits the accepted TLS
version to be used to negotiate the TLS communication.</p>
<p>On another hand, the <code class="docutils literal notranslate"><span class="pre">proxy_ssl_certificate</span></code> and
<code class="docutils literal notranslate"><span class="pre">proxy_ssl_certificate_key</span></code> define the certificate and key to be used by
NGINX for setting up a mTLS communication with the upstream server. Indeed, by
default, only the upstream server must authenticate with its certificate toward
NGINX. With both these directives, NGINX presents its own certificate to the
upstream server to ensure the upstream can authenticate the reverse proxy,
which could be used to perform authorization decisions.</p>
<p><strong>IP based protections</strong></p>
<p>When a client connects to NGINX, their IP address is retrieved and can be used
by NGINX to enforce restrictions based on different rules (geoIP, manually
defined decisions, etc.). <a class="reference internal" href="module3.html#module3-restrict-ip"><span class="std std-ref">Module 3</span></a> goes further
into details on how to restrict access based on IP addresses.</p>
<p><strong>HTTP specific security features</strong></p>
<p>HTTP and its evolution come with many specifications, headers and other quirks
dedicated to security. We could not go over all of them, but it is worth
mentioning some common hardening features allowed by NGINX. Ideally, the
upstream servers should be able to define the correct HTTP headers to ensure
secure content delivery: the upstream is the most tightly intertwined with the
application logic, it knows what content should be allowed and how. However,
the power of NGINX is its ability to cope with upstream server not able to add
such security options.</p>
<dl class="docutils">
<dt>Secure Cross-Origin Resources Sharing (CORS)</dt>
<dd><p class="first">The following diagram from <a class="reference external" href="https://developer.mozilla.org/en-US/docs/Web/http/CORS">Mozilla’s documentation</a> presents what is
meant by CORS and when it occurs.</p>
<a class="reference internal image-reference" href="../../_images/cors_principle.png"><img alt="Diagram presenting CORS principle" src="../../_images/cors_principle.png" style="height: 500px;" /></a>
<p>Basically, if your server serves resources from another domain (say, you host
images or scripts used as resources for pages in a website hosted at
<code class="docutils literal notranslate"><span class="pre">site1.example.com</span></code> and <code class="docutils literal notranslate"><span class="pre">site2.example.com</span></code>), you will need to enable
CORS for the web clients to be able to fetch the resources you host that are
referred to in the pages served by <code class="docutils literal notranslate"><span class="pre">site1.example.com</span></code> and
<code class="docutils literal notranslate"><span class="pre">site2.example.com</span></code>.</p>
<div class="last highlight-NGINX notranslate"><div class="highlight"><pre><span></span><span class="k">map</span> <span class="nv">$request_method</span> <span class="nv">$cors_method</span> <span class="p">{</span>
  <span class="kn">OPTIONS</span> <span class="mi">11</span><span class="p">;</span>
  <span class="kn">GET</span> <span class="mi">1</span><span class="p">;</span>
  <span class="kn">POST</span> <span class="mi">1</span><span class="p">;</span>
  <span class="kn">default</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">server</span> <span class="p">{</span>
  <span class="c1"># ...</span>
  <span class="kn">location</span> <span class="s">/</span> <span class="p">{</span>
    <span class="kn">if</span> <span class="s">(</span><span class="nv">$cors_method</span> <span class="p">~</span> <span class="sr">&#39;1&#39;)</span> <span class="p">{</span>
    <span class="kn">add_header</span> <span class="s">&#39;Access-Control-Allow-Methods&#39;</span>
      <span class="s">&#39;GET,POST,OPTIONS&#39;</span><span class="p">;</span>
    <span class="kn">add_header</span> <span class="s">&#39;Access-Control-Allow-Origin&#39;</span>
      <span class="s">&#39;*.example.com&#39;</span><span class="p">;</span>
    <span class="kn">add_header</span> <span class="s">&#39;Access-Control-Allow-Headers&#39;</span>
      <span class="s">&#39;DNT,</span> <span class="s">Keep-Alive,</span> <span class="s">User-Agent,</span> <span class="s">X-Requested-With,</span> <span class="s">If-Modified-Since,</span> <span class="s">Cache-Control,</span> <span class="s">Content-Type&#39;</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="kn">if</span> <span class="s">(</span><span class="nv">$cors_method</span> <span class="p">=</span> <span class="s">&#39;11&#39;)</span> <span class="p">{</span>
      <span class="kn">add_header</span> <span class="s">&#39;Access-Control-Max-Age&#39;</span> <span class="mi">1728000</span><span class="p">;</span>
      <span class="kn">add_header</span> <span class="s">&#39;Content-Type&#39;</span> <span class="s">&#39;text/plain</span><span class="p">;</span> <span class="kn">charset=UTF-8&#39;</span><span class="p">;</span>
      <span class="kn">add_header</span> <span class="s">&#39;Content-Length&#39;</span> <span class="mi">0</span><span class="p">;</span>
      <span class="kn">return</span> <span class="mi">204</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</dd>
<dt>Clickjacking and Cross-Site Scripting (XSS) protection</dt>
<dd>Clickjacking refers to an attack where a user is tricked into clicking on a
link from a different source that what they think (for example, clicking on a
“Submit” button inside an iFrame when they think the button belongs to the
top level page and not an iFrame). XSS is a security exploit which allows
an attacker to inject into a website malicious client-side code. This code is
executed by the victims and lets the attackers bypass access controls and
impersonate users. HTTP proposes the standardized <strong>Content-Security-Policy</strong>
header to solve these. This one consists of directives where the client
receives indication as of which resources are allowed to be fetched from
where. The <code class="docutils literal notranslate"><span class="pre">add_header</span> <span class="pre">Content-Security-Policy</span> <span class="pre">&quot;&lt;directive&gt;</span> <span class="pre">&lt;value&gt;;&quot;;</span></code>
NGINX directive allows setting up this header on HTTP responses served to the
client. The reader is advised to dig deeper in this topic by looking at
<a class="reference external" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy">documentation</a>
and <a class="reference external" href="https://content-security-policy.com/examples/nginx/">examples</a>.</dd>
<dt>HTTP Strict Transport Security</dt>
<dd>HTTP Strict Transport Security is an HTTP header indicating to a web client
that the host it contacted must be contacted through HTTPS only, and caches
this information for a certain (generally long) amount of time. This reduces
the attack surface available for an attacker in the middle aiming to
intercept initial plain HTTP requests and impersonate these. Indeed, after
this header is received once, the client is protected and knows that at least
for <code class="docutils literal notranslate"><span class="pre">max-age</span></code> seconds that a plain HTTP response is suspicious and should
not be trusted. In order to ensure this, NGINX can, with the directive
<code class="docutils literal notranslate"><span class="pre">add_header</span> <span class="pre">Strict-Transport-Security</span> <span class="pre">“max-age=31536000;</span> <span class="pre">includeSubDomains”</span>
<span class="pre">always;</span></code>, add the HTTP Strict-Transport-Security header to all responses
sent back to the client.</dd>
</dl>
<p><strong>Location security and secure links</strong></p>
<p>In order to protect a location, NGINX can make use of the features in its
<a class="reference external" href="https://nginx.org/en/docs/http/ngx_http_secure_link_module.html">ngx_http_secure_link_module</a>.</p>
<p>Basically, this module allows protecting a location by requiring the requested
URI contains some non easily guessable value, making it hard for automated
scanner to easily access the files at that location.</p>
<p>This can be implemented by 2 different modes: The first mode is enabled by the
<code class="docutils literal notranslate"><span class="pre">secure_link_secret</span></code> directive and is used to check authenticity of requested
links as well as protect resources from unauthorized access. The second mode
(0.8.50) is enabled by the <code class="docutils literal notranslate"><span class="pre">secure_link</span></code> and <code class="docutils literal notranslate"><span class="pre">secure_link_md5</span></code> directives
and is also used to limit lifetime of links.</p>
<p>The following configuration makes use of the <code class="docutils literal notranslate"><span class="pre">secure_link_secret</span></code> directive:</p>
<div class="highlight-NGINX notranslate"><div class="highlight"><pre><span></span><span class="k">location</span> <span class="s">/resources</span> <span class="p">{</span>
  <span class="kn">secure_link_secret</span> <span class="s">mySecret</span><span class="p">;</span>
  <span class="kn">if</span> <span class="s">(</span><span class="nv">$secure_link</span> <span class="p">=</span> <span class="s">&quot;&quot;)</span> <span class="p">{</span> <span class="kn">return</span> <span class="mi">403</span><span class="p">;</span> <span class="p">}</span>
  <span class="kn">rewrite</span> <span class="s">^</span> <span class="s">/secured/</span><span class="nv">$secure_link</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">location</span> <span class="s">/secured/</span> <span class="p">{</span>
  <span class="kn">internal</span><span class="p">;</span>
  <span class="kn">root</span> <span class="s">/var/www</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>In order to make use of a secure link, one must place the files to be protected
inside the <code class="docutils literal notranslate"><span class="pre">/var/www/secured</span></code> folder. With this in place, accessing, for
example, the <code class="docutils literal notranslate"><span class="pre">/var/www/secured/index.html</span></code> file would require using the
following URL:
<code class="docutils literal notranslate"><span class="pre">your.server.url/resources/a53bee08a4bf0bbea978ddf736363a12/index.html</span></code>. Here
is what happens when this request is received by NGINX:</p>
<ul class="simple">
<li>NGINX matches the location <code class="docutils literal notranslate"><span class="pre">/resources</span></code> from its configuration</li>
<li>It discovers this location is protected by a secret, as of the presence of
the <code class="docutils literal notranslate"><span class="pre">secure_link_secret</span></code> directive.</li>
<li>It takes the secret word (in that case, <code class="docutils literal notranslate"><span class="pre">mySecret</span></code>) and the remaining of
the accessed URI (in that case, <code class="docutils literal notranslate"><span class="pre">index.html</span></code>), concatenates those and
hashes it with the MD5 procedure. In bash, you could perform this operation
with the following code:</li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">echo</span> -n <span class="s1">&#39;index.htmlmySecret&#39;</span> <span class="p">|</span> openssl md5 -hex
</pre></div>
</div>
<ul class="simple">
<li>If the computed hash matches the string between <code class="docutils literal notranslate"><span class="pre">resources/</span></code> and
<code class="docutils literal notranslate"><span class="pre">/index.html</span></code> in the URI, it proceeds, otherwise it returns a 403 error.</li>
<li>After validating the URI, NGINX can <code class="docutils literal notranslate"><span class="pre">rewrite</span></code> the URI by replacing it (from
the beginning, per the <code class="docutils literal notranslate"><span class="pre">^</span></code> argument) by another location’s prefix (in that
case, <code class="docutils literal notranslate"><span class="pre">/secured/</span></code>) and appending the content of the <code class="docutils literal notranslate"><span class="pre">$secure_link</span></code>
variable. This variable contains, if the validation failed, an empty string,
and if the validation succeeded, the remaining of the URI after the hash (in
that case, <code class="docutils literal notranslate"><span class="pre">index.html</span></code>).</li>
<li>Making the location <code class="docutils literal notranslate"><span class="pre">/secured/</span></code> internal, only NGINX generated requests
(through internal redirects) can access it. Therefore, thanks to the above
<code class="docutils literal notranslate"><span class="pre">rewrite</span></code> directive, only secure links can reach the files located in the
secure folder, and the client accessing
<code class="docutils literal notranslate"><span class="pre">your.server.url/resources/a53bee08a4bf0bbea978ddf736363a12/index.html</span></code> can
in the end be served the file stored at <code class="docutils literal notranslate"><span class="pre">/var/www/secured/index.html</span></code>.</li>
</ul>
<p>Using the <code class="docutils literal notranslate"><span class="pre">secure_link</span></code> and <code class="docutils literal notranslate"><span class="pre">secure_link_md5</span></code> directives follows the same
general idea but with more control over some aspects of the link, notably
allowing to define an expiration date for example. The module documentation
covers it in more details.</p>
<p><strong>Logging</strong></p>
<p>Logging the important information of received requests is crucial to configure
your server’s security. This topic is covered in more details in <a class="reference internal" href="module3.html#module3-configure-logging"><span class="std std-ref">Module 3</span></a>.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="describe-the-difference-between-serving-static-content-and-dynamic-content-regex-and-variables">
<h3>1.3 - Describe the difference between serving static content and dynamic content. (REGEX, and variables)<a class="headerlink" href="#describe-the-difference-between-serving-static-content-and-dynamic-content-regex-and-variables" title="Permalink to this headline">¶</a></h3>
<p>This objective’s phrasing is quite weird: dynamic vs. static content clearly,
in the context of the web, refer to webpages that may have automated evolutions
and some logic (NodeJS or PHP web stack), while static content should remain
statically generated, independently of the requests. On another hand, the
parenthesis and sub-objectives go totally in another direction, talking about
NGINX’s location matching mechanisms. The following <a class="reference external" href="https://nginxcommunity.slack.com/archives/C071Y9G3L3T/p1720767284864229">link</a>
points to a discussion on this subject that you may find enlightening or not.</p>
<p>To answer both aspects:</p>
<ul class="simple">
<li>NGINX supports dynamic URI matching. This means that the configuration file
does not have to write one by one all possible URIs that a server should
answer to, but performs some smart matching potentially using REGEX and
variables. This is notably what we discussed in <a class="reference internal" href="#module2-configure-routing"><span class="std std-ref">1.2 - Describe how to
configure path REGEX routing</span></a>.</li>
<li>NGINX can act both as a static content server, and a dynamic content reverse
proxy. NGINX serves static files using the <code class="docutils literal notranslate"><span class="pre">root</span></code>, <code class="docutils literal notranslate"><span class="pre">index</span></code> and
<code class="docutils literal notranslate"><span class="pre">try_files</span></code> directives we already encountered. On another hand, the
<code class="docutils literal notranslate"><span class="pre">proxy_pass</span></code> family of directives allows NGINX to reverse proxy connections
to upstream servers generating dynamic content. NGINX even has optimized
proxy passing for certain protocols such as FastCGI with the
<cite>ngx_http_fastcgi_module
&lt;https://nginx.org/en/docs/http/ngx_http_fastcgi_module.html&gt;</cite> and its
<code class="docutils literal notranslate"><span class="pre">fastcgi_pass</span></code> directive.</li>
</ul>
<p>The difference between both is that:</p>
<ul class="simple">
<li>static file’s content should not be different between 2 requests. The content
should only evolve if someone replaces the files at the location they are
being served from on the machine hosting NGINX.</li>
<li>dynamic content is expected to serve different files between 2 requests. This
can for example be implemented with the PHP programming language that can
read a request and a <code class="docutils literal notranslate"><span class="pre">.php</span></code> file to be served, and perform dynamic actions
to make the page evolve depending on request’s parameters (e.g.:
Authorization, User-Agent or Cookie headers), or even depending on other
aspects (e.g.: the time at which the request is processed)</li>
</ul>
<p>NGINX has features for handling both aspects.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="describe-how-server-and-location-work">
<h3>1.3 - Describe how server and location work<a class="headerlink" href="#describe-how-server-and-location-work" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://nginx.org/en/docs/http/request_processing.html">https://nginx.org/en/docs/http/request_processing.html</a></p>
<p><a class="reference external" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages">https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages</a></p>
<p><a class="reference external" href="https://nginx.org/en/docs/http/server_names.html">https://nginx.org/en/docs/http/server_names.html</a></p>
<p><strong>Server and Location blocks</strong></p>
<p>For this objective, if you are already comfortable with the previous part you
should have a better idea on how to tackle this.</p>
<p>It however can be interesting to note the actual definition of server and
location blocks. First, note that the <code class="docutils literal notranslate"><span class="pre">server</span></code> directive belongs to both the
http and stream modules, while the <code class="docutils literal notranslate"><span class="pre">location</span></code> directive can only be found and
only makes sense in the http module (there is no notion of URI above the OSI
layer 7 where the HTTP protocol lies).</p>
<p><strong>Server</strong></p>
<p>A <code class="docutils literal notranslate"><span class="pre">server</span></code> block sets the configuration for a “Virtual Server” (if you come
from the F5 Big IP world, you can very easily compare these to the LTM Virtual
Servers). It is “virtual”, in the sense that there are not really one server
process and stack per server bloc, NGINX makes sure to optimize this part, and
it is a “server”, in the sense that it listens to incoming requests. The most
amazing part about how NGINX treats <code class="docutils literal notranslate"><span class="pre">server</span></code> block lies in how requests are
processed and assigned to a virtual server: instead of just considering an
IP+Port association to define uniquely a server, NGINX is able to consider
other aspects. This means that N servers may be able to listen on the same
IP+Port pair, but NGINX will still be able to correctly associate requests to
one or another depending on the context.</p>
<ul class="simple">
<li>TLS SNI: on a stream or http server using TLS, NGINX is able to associate
requests by reading the TLS’ extension “Server Name Identification” (SNI) if
it is compiled with the correct options (you can check the output of <code class="docutils literal notranslate"><span class="pre">nginx</span>
<span class="pre">-V</span></code> and see if there is mention of SNI in the options).</li>
<li>HTTP Host header: on a http server only, NGINX can read from the request’s
header “Host” the value and associate the request to a specific server block
if it can match this value to a server’s <code class="docutils literal notranslate"><span class="pre">server_name</span></code>. Note that
<code class="docutils literal notranslate"><span class="pre">server_name</span></code> support wildcard (*) so you may catch many hostnames with a
single server block.</li>
</ul>
<p><strong>Location</strong></p>
<p>A location is another concept. It first can only live inside a server block
living in a http block, and it uses the HTTP request target from the HTTP
Request line to define which location should be matched.</p>
<p>Recall the content from <a class="reference internal" href="#module2-configure-routing"><span class="std std-ref">URI routing part</span></a> to
learn about the different quirks and possibilities for making dynamic routing
between different location block inside a server.</p>
<p>Locations differ from server in that they are binded to a server, location
blocks only exist in the context of a server. When a request is coming to
NGINX, it first maps it to a virtual server, and then eventually matches a
location inside that server to define how to process the request. Both are
blocks that can contain various directives to give specifications on how to
process incoming requests.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="explain-what-is-unique-to-nginx-as-a-web-server">
<h3>1.3 - Explain what is unique to NGINX as a web server<a class="headerlink" href="#explain-what-is-unique-to-nginx-as-a-web-server" title="Permalink to this headline">¶</a></h3>
<p>There are of course many ways to see why NGINX is unique as a web server. I
notably think, regarding the points we studied for this objective, the 3 most
important ones are the following:</p>
<ul class="simple">
<li>Performance: NGINX is reputably known for its performances. As written by
<a class="reference external" href="https://aosabook.org/en/v2/nginx.html">Andrew Alexeev</a>, NGINX was written
with in mind solving the <a class="reference external" href="https://en.wikipedia.org/wiki/C10k_problem">C10K problem</a> at a time this could barely be
achieved with Apache. Therefore, NGINX has performance in its core design and
handles requests in an optimized way (mostly on BSD and Linux based
platforms). This sets it apart from its historical ancestor Apache.</li>
<li>Security: NGINX comes with many security features as you could see in this
part. The most powerful one probably is implementing HTTPS and making it
quite easy to set up with reasonably secure defaults: you just need to provide
a path to a key and a certificate, NGINX can handle the rest. This is not
especially rare in reverse proxies, but NGINX, with its design and all other
controls it gives for security, is a reputably secure reverse proxy.</li>
<li>Flexibility: The previous part emphasizes how you can, with simple and file
based directives, define complex and useful behaviour matching various
possible architectures for your application delivery. If you come from the F5
Big IP world, you probably blew your mind realizing you do not need to have a
virtual server dedicated to routing: you can here directly create a virtual
server per application and make them all listen on HTTP/HTTPS standard ports
while letting NGINX match request to virtual server using SNI or Host header.</li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
</div>
<div class="section" id="objective-configure-nginx-as-a-reverse-proxy">
<h2>Objective - Configure NGINX as a reverse proxy<a class="headerlink" href="#objective-configure-nginx-as-a-reverse-proxy" title="Permalink to this headline">¶</a></h2>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<div class="section" id="explain-how-traffic-routing-is-handled-in-nginx-as-a-reverse-proxy">
<h3>1.4 - Explain how traffic routing is handled in NGINX as a reverse proxy<a class="headerlink" href="#explain-how-traffic-routing-is-handled-in-nginx-as-a-reverse-proxy" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://nginx.org/en/docs/http/request_processing.html">https://nginx.org/en/docs/http/request_processing.html</a></p>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy/">https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy/</a></p>
<p><a class="reference external" href="https://nginx.org/en/docs/http/ngx_http_upstream_module.html">https://nginx.org/en/docs/http/ngx_http_upstream_module.html</a></p>
<p><strong>Routing to upstream in NGINX</strong></p>
<p>As you have seen from the previous Objective, routing in NGINX begins be
assigning a request to a virtual server, then to a location block in the case
of and http server.</p>
<p>In the case of a reverse proxy, the same applies, the difference lies in the
request’s proxying to an upstream server. Inside a location block, you can pass
a request to upstream server using the <code class="docutils literal notranslate"><span class="pre">proxy_pass</span></code> directive. Other
<code class="docutils literal notranslate"><span class="pre">*_pass</span></code> directive allow to pass to non HTTP upstream servers. The remaining
of the routing depends on this communication with the upstream server.</p>
<p>Note that you can not only pass to a specific upstream address or domain, but
also to an upstream group, defined by the <code class="docutils literal notranslate"><span class="pre">upstream</span></code> directive. Recall what
you learnt in the <a class="reference internal" href="module1.html#module-1-nginx-load-balancer"><span class="std std-ref">Previous module</span></a> to know
about how the load balancing is handled and which server is selected for
sending the request to.</p>
<p><strong>Specificities and quirks related to upstream routing</strong></p>
<p>The following points are hard to organize and classify as they are quite
specific to NGINX and how to pass requests upstream in details, but you may
find these interesting and will probably some day encounter issues related to
these:</p>
<ul class="simple">
<li>Passing request headers: by default, NGINX redefines two header fields in
proxied requests, “Host” and “Connection”, and eliminates the header fields
whose values are empty strings. “Host” is set to the $proxy_host variable,
and “Connection” is set to close. This can be a source of L7 routing issues
because your upstream server may need to know the original Host header sent
by the client, or have other information such as the client’s real IP address
(indicated by HTTP headers such as X-Real-IP, X-Forwarded-For, or Forwarded).
To solve these, you can use the <code class="docutils literal notranslate"><span class="pre">proxy_set_header</span></code> directive.</li>
<li>Choosing an outgoing IP address. Because your NGINX instance may be reachable
through multiple IPs, you may need to give specific source IP to your
upstream server for tackling routing issues. The <code class="docutils literal notranslate"><span class="pre">proxy_bind</span></code> directive
solves precisely this.</li>
<li>Dynamically resolving upstream’s IP. By default, if you put your upstream
servers in an <code class="docutils literal notranslate"><span class="pre">upstream</span></code> group, you can use the <code class="docutils literal notranslate"><span class="pre">server</span></code> directive to
define your upstream servers by the IP, domain name or UNIX socket address.
Note that the domain name resolution, by default, only occurs on NGINX
configuration reload, and does not monitor changes made to the DNS record
before the next reload. This can be solved in NGINX Plus commercial
subscription, with the <code class="docutils literal notranslate"><span class="pre">resolve</span></code> option of the <code class="docutils literal notranslate"><span class="pre">server</span></code> directive, but
not easily and cleanly in NGINX OSS. If your domain name resolves to multiple
IP addresses, NGINX will consider multiple upstream server and round-robin
through them as if you added each IP by hand.</li>
<li>Caching and upstream bypassing. If you configure caching of upstream server’s
responses, requests are not necessarily proxied to upstream server and may
totally bypass this step, cutting the routing path at NGINX.</li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="explain-what-is-unique-to-nginx-as-a-reverse-proxy">
<h3>1.4 - Explain what is unique to NGINX as a reverse proxy<a class="headerlink" href="#explain-what-is-unique-to-nginx-as-a-reverse-proxy" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://medium.com/&#64;mak0024/nginx-as-a-reverse-proxy-benefits-and-best-practices-928863bfd317">https://medium.com/&#64;mak0024/nginx-as-a-reverse-proxy-benefits-and-best-practices-928863bfd317</a></p>
<p><strong>NGINX strengths</strong></p>
<p>NGINX is unique as a reverse proxy by how it exploits its strengths. Here are
some points recalling how NGINX especially shines:</p>
<ul class="simple">
<li>Performance: as we explained regarding the Web Server capabilities of NGINX,
performances are crucial for a reverse proxy and NGINX can leverage its web
server performances in that regard. Notably, NGINX can be configured with
different proxy passing protocols, optimized for certain tasks which makes
NGINX a powerful reverse proxy. NGINX can also manage caching easily and use
cached response to answer faster and reduce load on the upstream servers.</li>
<li>Flexibility: as we have seen with NGINX as a web server, NGINX configuration
is flexible. This also benefits the reverse proxy aspects of NGINX, as it
allows us to easily make operations such as manipulating headers, load
balancing, handle upstream errors etc. All the NGINX configuration can easily
be tracked with the configuration files which is a great strength of NGINX.</li>
<li>Security features: reverse proxies have the ability to act as Web Application
Firewall, which, to some small but powerful extends, applies to NGINX.
Indeed, rate limiting, IP restrictions, HTTP endpoints and methods
restrictions are all part of NGINX tools for protecting the upstream servers.</li>
</ul>
<p>Some of these features can be found in other products, but NGINX particularly
shines in grouping them all together in a lightweight and Open Source software.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="configure-encryption">
<h3>1.4 - Configure encryption<a class="headerlink" href="#configure-encryption" title="Permalink to this headline">¶</a></h3>
<p>DEJONGHE, NGINX COOKBOOK Advanced Recipes for High -Performance Load
Balancing., 77, 84-88.</p>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/security-controls/securing-http-traffic-upstream/">https://docs.nginx.com/nginx/admin-guide/security-controls/securing-http-traffic-upstream/</a></p>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/security-controls/securing-tcp-traffic-upstream/">https://docs.nginx.com/nginx/admin-guide/security-controls/securing-tcp-traffic-upstream/</a></p>
<p>In the context of this part, configuring encryption specifically for reverse
proxying seems to refer to encrypting traffic between NGINX and the upstream
servers (configuring encryption between the client and NGINX is covered in the
<a class="reference internal" href="#module2-securely-serve-content"><span class="std std-ref">Web Server part</span></a>)</p>
<p><strong>Securing HTTP traffic to upstream</strong></p>
<p>To encrypt HTTP traffic to upstream servers, the simplest configuration is to
specify “<a class="reference external" href="https://">https://</a>” in front of the server in option to the <code class="docutils literal notranslate"><span class="pre">proxy_pass</span></code>
directive. This will make sure, as long as upstream servers can present an
HTTPS certificate, that the communication is encrypted.</p>
<p>Note however that, regarding authentication, by default NGINX does not verify
with its CAs the signature of the presented certificate. <code class="docutils literal notranslate"><span class="pre">proxy_ssl_verify</span></code>
option allows enforcing this.</p>
<p><strong>Securing TCP traffic to upstream</strong></p>
<p>Similarly to the above for HTTPS, you may use SSL in TCP to encrypt layer 4
stream to upstream servers, it being HTTP or not. In that case, you should not
specify HTTP but just add another directive in the same block as your
<code class="docutils literal notranslate"><span class="pre">proxy_pass</span></code> directive: <code class="docutils literal notranslate"><span class="pre">proxy_ssl</span>&#160; <span class="pre">on;</span></code>.</p>
<p>Again, the upstream’s certificate is not verified by default, which should be
enabled by <code class="docutils literal notranslate"><span class="pre">proxy_ssl_verify</span> <span class="pre">on;</span></code>.</p>
<p>Note that here, as the objective only specifies “encryption”, we do not focus
on authentication. For making NGINX authenticate toward the upstream servers,
take a look at the <a class="reference internal" href="module3.html#module3-configure-certificates"><span class="std std-ref">Certificate related section of module 3</span></a></p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="demonstrate-how-to-manipulate-headers">
<h3>1.4 - Demonstrate how to manipulate headers<a class="headerlink" href="#demonstrate-how-to-manipulate-headers" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_set_header">https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_set_header</a></p>
<p><a class="reference external" href="https://nginx.org/en/docs/http/ngx_http_headers_module.html">https://nginx.org/en/docs/http/ngx_http_headers_module.html</a></p>
<p><strong>Modify response headers produced by upstream before they reach the client</strong></p>
<p>In the context of NGINX being used as a reverse proxy, to manipulate headers in
NGINX, there are 2 main approaches: modifying headers from the upstream
received response, or modifying the request headers before they are passed to
the upstream server.</p>
<p>You can add as many headers as desired to a response using the directives from
the <code class="docutils literal notranslate"><span class="pre">ngx_http_headers_module</span></code>.</p>
<div class="highlight-NGINX notranslate"><div class="highlight"><pre><span></span><span class="k">add_header</span> <span class="s">Cache-Control</span> <span class="s">private</span><span class="p">;</span>
</pre></div>
</div>
<p>Adds a “Cache-Control” header with the “private” value (which indicates that
the response is client specific and can be cached but not in a cache shared
among users).</p>
<p>To remove headers from a response, the <code class="docutils literal notranslate"><span class="pre">proxy_hide_header</span></code> allows removing
any specified from the response. Note that by default, “Date”, “Server”,
“X-Pad” and “X-Accel-…” headers are removed.</p>
<p><code class="docutils literal notranslate"><span class="pre">proxy_ignore_headers</span></code> allows making NGINX ignore headers that would
otherwise instruct it to perform some actions (redirects, cache control, etc.).
The following fields can be ignored: “X-Accel-Redirect”, “X-Accel-Expires”,
“X-Accel-Limit-Rate” (1.1.6), “X-Accel-Buffering” (1.1.6), “X-Accel-Charset”
(1.1.6), “Expires”, “Cache-Control”, “Set-Cookie” (0.8.44), and “Vary” (1.7.7).</p>
<p><strong>Modify the request headers produced by client before they reach the upstream
server</strong></p>
<p>On the other side, you may want to modify HTTP headers before they could reach
the upstream server. For this, your main tool is the <code class="docutils literal notranslate"><span class="pre">proxy_set_header</span></code>
directive. As the name suggests, it does not just add headers but allows
redefining the received headers.</p>
<p>By default, 2 fields are automatically redefined, as if the following
directives were a default:</p>
<div class="highlight-NGINX notranslate"><div class="highlight"><pre><span></span><span class="k">proxy_set_header</span> <span class="s">Host</span>       <span class="nv">$proxy_host</span><span class="p">;</span>
<span class="k">proxy_set_header</span> <span class="s">Connection</span> <span class="s">close</span><span class="p">;</span>
</pre></div>
</div>
<p>This allows to use the upstream’s server name as Host (you will very often need
to redefine this to <code class="docutils literal notranslate"><span class="pre">$host</span></code> or <code class="docutils literal notranslate"><span class="pre">$http_host</span></code> in order for the upstream
server to see the client’s original requested Host). It also ensures the
connection is closed after the transaction and prevents keeping unwanted
keepalived connections. This makes sure that Keep-Alive is explicitly
configured.</p>
<p>By default, the request headers received by the client are passed, but this can
be modified through the <code class="docutils literal notranslate"><span class="pre">proxy_pass_request_header</span></code> directive.</p>
<p>If you want to explicitly prevent one specific header from being passed to the
upstream, the following allows you to do so:</p>
<div class="highlight-NGINX notranslate"><div class="highlight"><pre><span></span><span class="k">proxy_set_header</span> <span class="s">Accept-Encoding</span> <span class="s">&quot;&quot;</span><span class="p">;</span>
</pre></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="describe-the-difference-between-proxy-set-header-and-add-header">
<h3>1.4 - Describe the difference between proxy_set_header and add_header<a class="headerlink" href="#describe-the-difference-between-proxy-set-header-and-add-header" title="Permalink to this headline">¶</a></h3>
<p>You may have got it from the above, but basically <code class="docutils literal notranslate"><span class="pre">proxy_set_header</span></code> modifies
the request headers before they are passed to upstream, while <code class="docutils literal notranslate"><span class="pre">add_header</span></code>
adds headers to the response sent to the client.</p>
<p>They are not operating on the same aspects of HTTP (request vs. response).</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="id1">
<h3>1.4 - Modify or tune a memory zone configuration<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/#sharing-data-with-multiple-worker-processes">https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/#sharing-data-with-multiple-worker-processes</a></p>
<p><a class="reference external" href="https://nginx.org/en/docs/http/ngx_http_upstream_module.html#zone">https://nginx.org/en/docs/http/ngx_http_upstream_module.html#zone</a></p>
<p><strong>Memory zone for reverse proxying</strong></p>
<p>Shared memory zones in the context of NGINX can be used in multiple contexts
(shared rate limiting, shared caching, shared upstream state, etc.)</p>
<p>In the context of NGINX being used as a reverse proxy, we will assume here that
memory zone here refers to the memory zone to be defined in the <code class="docutils literal notranslate"><span class="pre">upstream</span> <span class="pre">{}</span></code>
block context (as other usages seem more related to other uses of NGINX).</p>
<p>Shared memory zones in the context of upstream groups allow NGINX to share
information and state related to the upstream load balancing state among the
different workers. As explained in <a class="reference internal" href="module1.html#module1-shared-memory-zones"><span class="std std-ref">the module 1</span></a>, sharing memory zones is an efficient way for NGINX to share
information among its workers and prevent redoing the same work when successive
requests are handled by different workers. For example, if an upstream group
contains 4 members, and we want the N NGINX workers to load balance between
these upstream servers in a round robin fashion, the N NGINX workers need to
make sure they don’t all re-do the round-robin work, but rather hit each server
one after the other. Shared memory zone allow for example to do this.</p>
<p><strong>Modify or tune a shared memory zone of an upstream group</strong></p>
<p>Defining a shared memory zone for the upstream context is done with the
<code class="docutils literal notranslate"><span class="pre">zone</span></code> directive. It accepts 2 parameters: a name, required, and a size,
optional. Using the same name for different zones allows to reuse a shared
memory zone (eventually to optimize the used memory). For the size parameter,
fine tuning it depends on multiple parameters, the documentation however
provides some guidance on how it can be optimized for the use cases:</p>
<p>As an example, with the sticky_route session persistence method and a single
health check enabled, a 256-KB zone can accommodate information about the
indicated number of upstream servers:</p>
<ul class="simple">
<li>128 servers (each defined as an IP-address:port pair)</li>
<li>88 servers (each defined as hostname:port pair where the hostname resolves to
a single IP address)</li>
<li>12 servers (each defined as hostname:port pair where the hostname resolves to
multiple IP addresses)</li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="describe-how-to-configure-nginx-as-socket-reverse-proxy">
<h3>1.4 - Describe how to configure NGINX as socket reverse proxy<a class="headerlink" href="#describe-how-to-configure-nginx-as-socket-reverse-proxy" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://nginx.org/en/docs/http/websocket.html">https://nginx.org/en/docs/http/websocket.html</a></p>
<p><strong>Web sockets in NGINX</strong></p>
<p>In order to use NGINX as a reverse proxy when your backend server uses web
sockets will work easily. You however must apply a specific configuration:
since the “Upgrade” HTTP header, used to configure web sockets, is a hop-by-hop
header, it is not expected to be passed by default from the client to the
upstream servers.</p>
<p>To handle this, NGINX uses a special procedure that can be configured with the
following example code:</p>
<div class="highlight-NGINX notranslate"><div class="highlight"><pre><span></span><span class="k">http</span> <span class="p">{</span>
  <span class="kn">map</span> <span class="nv">$http_upgrade</span> <span class="nv">$connection_upgrade</span> <span class="p">{</span>
      <span class="kn">default</span> <span class="s">upgrade</span><span class="p">;</span>
      <span class="kn">&#39;&#39;</span>      <span class="s">close</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="kn">server</span> <span class="p">{</span>
      <span class="kn">...</span>

      <span class="s">location</span> <span class="s">/chat/</span> <span class="p">{</span>
          <span class="kn">proxy_pass</span> <span class="s">http://backend</span><span class="p">;</span>
          <span class="kn">proxy_http_version</span> <span class="mi">1</span><span class="s">.1</span><span class="p">;</span>
          <span class="kn">proxy_set_header</span> <span class="s">Upgrade</span> <span class="nv">$http_upgrade</span><span class="p">;</span>
          <span class="kn">proxy_set_header</span> <span class="s">Connection</span> <span class="nv">$connection_upgrade</span><span class="p">;</span>
      <span class="p">}</span>
  <span class="p">}</span>
</pre></div>
</div>
<p>Here, the usage of <code class="docutils literal notranslate"><span class="pre">proxy_set_header</span></code> allows to override the “Upgrade” and
the “Connection” header to reflect the client’s intentions. The client’s
intention are read from the “Upgrade” header and put in a new variable
<code class="docutils literal notranslate"><span class="pre">$connection_upgrade</span></code>.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="describe-how-open-source-nginx-handles-health-checks-in-different-situations">
<h3>1.4 - Describe how open source NGINX handles health checks in different situations<a class="headerlink" href="#describe-how-open-source-nginx-handles-health-checks-in-different-situations" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/load-balancer/http-health-check/">https://docs.nginx.com/nginx/admin-guide/load-balancer/http-health-check/</a></p>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/load-balancer/tcp-health-check/">https://docs.nginx.com/nginx/admin-guide/load-balancer/tcp-health-check/</a></p>
<p><a class="reference external" href="https://docs.nginx.com/nginx/admin-guide/load-balancer/udp-health-check/">https://docs.nginx.com/nginx/admin-guide/load-balancer/udp-health-check/</a></p>
<p><a class="reference external" href="https://nginx.org/en/docs/http/ngx_http_upstream_module.html#server">https://nginx.org/en/docs/http/ngx_http_upstream_module.html#server</a></p>
<p><strong>NGINX OSS handles passive health checks</strong></p>
<p>First, as the certification cover NGINX OSS only, note that many features
related to health checks are therefore not covered (active health checks,
server drains, slow starts, etc.).</p>
<p>NGINX handling passive health checks means that, when reverse-proxying
connections, if it realizes that the upstream server does not respond, it will
not stand there and keep sending new connections to this backend. NGINX will
internally flag this server as down for a certain amount of time, and not send
requests to it again until it gets considered up again.</p>
<p>If the upstream group is in a shared memory zone, the upstream servers’ state
is shared among NGINX workers, making the server unavailability available to
all workers and preventing, when having N workers, having N times trials to
proxy client request to a failed server but do this only once.</p>
<p>The handling of health check is quite similar for each protocol (HTTP, TCP or
UDP).</p>
<p>Health check are handled only when using upstream block. The <code class="docutils literal notranslate"><span class="pre">server</span></code>
directive has options to precise health check behaviour for a certain server:
<code class="docutils literal notranslate"><span class="pre">max_fails</span></code> and <code class="docutils literal notranslate"><span class="pre">fail_timeout</span></code>.</p>
<p>In the following example, if NGINX fails to send a request to a server or does
not receive a response from it 3 times in 30 seconds, it marks the server as
unavailable for 30 seconds:</p>
<div class="highlight-NGINX notranslate"><div class="highlight"><pre><span></span><span class="k">upstream</span> <span class="s">backend</span> <span class="p">{</span>
  <span class="kn">server</span> <span class="s">backend1.example.com</span><span class="p">;</span>
  <span class="kn">server</span> <span class="s">backend2.example.com</span> <span class="s">max_fails=3</span> <span class="s">fail_timeout=30s</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Note that if there is only a single server in a group, the fail_timeout and
max_fails parameters are ignored, and the server is never marked unavailable.</p>
<p>By default, <code class="docutils literal notranslate"><span class="pre">max_fails=1</span></code> and <code class="docutils literal notranslate"><span class="pre">fail_timeout=10s</span></code>. Also note that
<code class="docutils literal notranslate"><span class="pre">fail_timeout</span></code> defines both, the time NGINX waits before considering the
server timed out, and the time during which a server is flagged as down after
it has reached that timeout. This aspect can be surprising.</p>
<p><strong>Health checking for HTTP, TCP and UDP upstream servers</strong></p>
<p>HTTP, TCP and UDP passive health checks are configured with the same
parameters, the only difference is that the upstream server group would be
created in a <code class="docutils literal notranslate"><span class="pre">stream</span></code> or a <code class="docutils literal notranslate"><span class="pre">http</span></code> block.</p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
</div>
</div>


     </div>
    
     <div class="row next-prev-btn-row">
       <div class="col-lg-12">
       
        <a href="module1.html" title="F5N1 - Management" accesskey="p" class="btn btn-primary left"><i class="fa fa-arrow-circle-left" aria-hidden="true"></i> Previous</a>
       
       
          <a href="module3.html" title="F5N3 - Configuration: Demonstrate" accesskey="n" class="btn btn-primary right">Next <i class="fa fa-arrow-circle-right" aria-hidden="true"></i></a>
       
     </div>
     </div>
    

    </article>
  </div>

</div>


  <div id="clouddocs-footer"></div>
  <!-- Bootstrap core JavaScript
  ================================================== -->
  <!-- Placed at the end of the document so the pages load faster -->

  <script src="../../_static/js/index.js"></script>
  <script src="../../_static/js/jquery.appear.js"></script>
  <script src="../../_static/js/printThis.js"></script>
  <script src="../../_static/js/bootstrap.min.js"></script>
  <script src="../../_static/js/clouddocs.js"></script>
  <script src="../../_static/js/CoveoJsSearch.Lazy.min.js"></script>
  </body>
</html>